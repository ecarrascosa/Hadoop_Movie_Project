# Hadoop_Movie_Project

Developed a Mapreduce application in Hadoop to gain insights into the movies of the year for 2018. The application includes map and reduce functions, a driver program to run the job as well as a Java scrapper that gets the raw data. The mapper includes a user-defined counter that counts the combined number of days that either Deadpool 2 or Aquaman remained in the top spot for revenue generation in a single day in 2018, and the reduce function includes a reduce-side join operation that merges the data from two datasets into one dataset that is then analyzed. The application runs on the Apache Hadoop Distributed File System (HDFS).

## Java scrapper

The scrapper extracts the day of the year in 2018 and the top grossing movie for that day from www.BoxOfficeMojo.com and stores it in a file called movie.txt

## The mapper and reducer

The mapper takes as input two files: the file created from the Java Scrapper called movie.txt and another file named revenue.txt containing the movie name and the gross revenue generated by that movie in 2018. It then outputs the movie name as the relevant join key into the Reducer which then combines the records from both datasets by key generating a single dataset containing the movie name, gross revenues generated by that movie in 2018 and the number of days that movie remained in the top spot for revenue generation in 2018. This is called a Reduce-side join with a single mapper. 

The reduce function finds the average gross revenue per movie in 2018 as well as the minimum and maximum gross revenue generated by a movie in a single day. 

FIles included:

- Mapper function
- Reducer function
- Driver code
Java Scrapper
movie.txt (Output from the Java Scrapper containing movie name and day of the year)
revenue.txt (file containing movie name and gross revenue for 2018)
Screenshot of Reducer output (movie name, gross revenue, # of days in top spot)
Screenshot of Counter output




